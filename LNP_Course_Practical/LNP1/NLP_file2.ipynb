{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "225f12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Embedding, LSTM, RepeatVector, Dropout, Bidirectional, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7a10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mxnet\n",
    "#!pip install d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736c32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mxnet import np, npx\n",
    "from d2l import mxnet as d2l\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e5120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bebb9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/fra-eng.zip from http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip...\n",
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "#@save\n",
    "def read_data_nmt():\n",
    "    \"\"\"Load the English-French dataset.\"\"\"\n",
    "    data_dir = d2l.download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda9fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6061ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 64 #Batch size for training\n",
    "epochs = 100 # number of epochs to train for\n",
    "latent_dimension = 250 # Letent dimensionality of the encoder space\n",
    "number_samples = 10000 # Number of samples to train on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684117f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça alors !\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"Preprocess the English-French dataset.\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # Replace non-breaking space with space, and convert uppercase letters to\n",
    "    # lowercase ones\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # Insert space between words and punctuation marks\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a15d1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"Tokenize the English-French dataset.\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "source, target = tokenize_nmt(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc364f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go', '.'], ['hi', '.'], ['run', '!'], ['run', '!'], ['who', '?']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b84b8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['va', '!'], ['salut', '!'], ['cours', '!'], ['courez', '!'], ['qui', '?']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "778b908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167130"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9246fa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167130"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4554999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipympl\n",
    "#!pip install mpl_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e50f3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c6864",
   "metadata": {},
   "source": [
    "Let us plot the histogram of the number of tokens per text sequence. In this simple English-French dataset, most of the text sequences have fewer than 20 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39901233",
   "metadata": {},
   "source": [
    "#@save\n",
    "\n",
    "def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
    "    \"\"\"Plot the histogram for list length pairs.\"\"\"\n",
    "    d2l.set_figsize()\n",
    "    _, _, patches = d2l.plt.hist(\n",
    "        [[len(l) for l in xlist], [len(l) for l in ylist]])\n",
    "    d2l.plt.xlabel(xlabel)\n",
    "    d2l.plt.ylabel(ylabel)\n",
    "    for patch in patches[1].patches:\n",
    "        patch.set_hatch('/')\n",
    "    d2l.plt.legend(legend)\n",
    "\n",
    "show_list_len_pair_hist(['source', 'target'], '# tokens per sequence','count', source, target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5091b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
